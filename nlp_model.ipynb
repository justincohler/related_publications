{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python Modules\n",
    "import os, math, random, copy, re\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# SQL Modules\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "# Scientific Modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.test.utils import common_texts\n",
    "\n",
    "# My Modules\n",
    "import scholar\n",
    "from db import db_connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\justincohler\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine = db_connect()\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "papers_df = pd.read_sql_table(\"paper\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>links</th>\n",
       "      <th>search_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Scikit-learn: Machine learning in Python</td>\n",
       "      <td>Scikit-learn is a Python module integrating a ...</td>\n",
       "      <td>16626</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Pattern recognition and machine learning</td>\n",
       "      <td>1.2 Probability Theory . . . . . . . . . . . ....</td>\n",
       "      <td>35819</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Gaussian processes in machine learning</td>\n",
       "      <td>We give a basic introduction to Gaussian Proce...</td>\n",
       "      <td>14392</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Machine learning in automated text categorization</td>\n",
       "      <td>The automated categorization (or classificatio...</td>\n",
       "      <td>9207</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Machine learning</td>\n",
       "      <td>If computers could loam from experiencetheirus...</td>\n",
       "      <td>3591</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   1           Scikit-learn: Machine learning in Python   \n",
       "1   2           Pattern recognition and machine learning   \n",
       "2   3             Gaussian processes in machine learning   \n",
       "3   4  Machine learning in automated text categorization   \n",
       "4   5                                   Machine learning   \n",
       "\n",
       "                                            abstract  links search_term  \n",
       "0  Scikit-learn is a Python module integrating a ...  16626        None  \n",
       "1  1.2 Probability Theory . . . . . . . . . . . ....  35819        None  \n",
       "2  We give a basic introduction to Gaussian Proce...  14392        None  \n",
       "3  The automated categorization (or classificatio...   9207        None  \n",
       "4  If computers could loam from experiencetheirus...   3591        None  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lemmatize(wordnet, sentence):\n",
    "       \n",
    "    sentence = re.sub('[!?:.,;@#$]', '', sentence)\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    \n",
    "    new_sentence = \"\"\n",
    "    for word in words:\n",
    "        new_sentence += wordnet.lemmatize(word) + \" \"\n",
    "    \n",
    "    return new_sentence.strip()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nltk.download() # Download models, corpus, etc.\n",
    "porter = PorterStemmer()\n",
    "wordnet = WordNetLemmatizer()\n",
    "\n",
    "papers_df[\"cleaned\"] = papers_df.abstract.apply(lambda x: porter.stem(x))\n",
    "papers_df.cleaned = papers_df.cleaned.apply(lambda x: lemmatize(wordnet, x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>links</th>\n",
       "      <th>search_term</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>652</td>\n",
       "      <td>Toward harnessing user feedback for machine le...</td>\n",
       "      <td>There has been little research into how end us...</td>\n",
       "      <td>104</td>\n",
       "      <td>None</td>\n",
       "      <td>there ha been little research into how end use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>653</td>\n",
       "      <td>Recent advances in predictive (machine) learning</td>\n",
       "      <td>Prediction involves estimating the unknown val...</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>prediction involves estimating the unknown val...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>654</td>\n",
       "      <td>Credit rating by hybrid machine learning techn...</td>\n",
       "      <td>It is very important for financial institution...</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>it is very important for financial institution...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>655</td>\n",
       "      <td>Machine learning algorithms for damage detecti...</td>\n",
       "      <td>The goal of this article is to detect structur...</td>\n",
       "      <td>142</td>\n",
       "      <td>None</td>\n",
       "      <td>the goal of this article is to detect structur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>656</td>\n",
       "      <td>ADVISOR: A machine learning architecture for i...</td>\n",
       "      <td>We have constructed ADVISOR, a two-agent machi...</td>\n",
       "      <td>118</td>\n",
       "      <td>None</td>\n",
       "      <td>we have constructed advisor a two-agent machin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title  \\\n",
       "640  652  Toward harnessing user feedback for machine le...   \n",
       "641  653   Recent advances in predictive (machine) learning   \n",
       "642  654  Credit rating by hybrid machine learning techn...   \n",
       "643  655  Machine learning algorithms for damage detecti...   \n",
       "644  656  ADVISOR: A machine learning architecture for i...   \n",
       "\n",
       "                                              abstract  links search_term  \\\n",
       "640  There has been little research into how end us...    104        None   \n",
       "641  Prediction involves estimating the unknown val...    100        None   \n",
       "642  It is very important for financial institution...    100        None   \n",
       "643  The goal of this article is to detect structur...    142        None   \n",
       "644  We have constructed ADVISOR, a two-agent machi...    118        None   \n",
       "\n",
       "                                               cleaned  \n",
       "640  there ha been little research into how end use...  \n",
       "641  prediction involves estimating the unknown val...  \n",
       "642  it is very important for financial institution...  \n",
       "643  the goal of this article is to detect structur...  \n",
       "644  we have constructed advisor a two-agent machin...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE=5000\n",
    "\n",
    "def tag_documents(row):\n",
    "    return TaggedDocument(row[\"cleaned\"], row.index)\n",
    "\n",
    "documents = papers_df.apply(lambda row: tag_documents(row), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\justincohler\\AppData\\Roaming\\Python\\Python36\\site-packages\\gensim\\models\\base_any2vec.py:743: UserWarning: C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  \"C extension not loaded, training will be slow. \"\n"
     ]
    }
   ],
   "source": [
    "model = Doc2Vec(documents, vector_size=5, window=2, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03058965,  0.02694721,  0.01240169, -0.01793071,  0.08863635],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.infer_vector([\"hello\", \"world\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_XY(df):\n",
    "    Y = df.links\n",
    "    X = df.drop('links', axis=1)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, Y = split_XY(papers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(645, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(5, input_dim=5, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "estimator = KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=5, verbose=0)\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(estimator, X, Y, cv=kfold)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
